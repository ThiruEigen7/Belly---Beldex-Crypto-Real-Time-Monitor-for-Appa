# ğŸ¯ BELLY - Beldex Crypto Real-Time Monitor

**Production-Ready Cryptocurrency Monitoring System**

Real-time price tracking, analytics, and ML predictions for Beldex (BDX) cryptocurrency.

---

## ğŸ“‹ Table of Contents

- [Architecture](#-architecture)
- [Features](#-features)
- [Prerequisites](#-prerequisites)
- [Quick Start](#-quick-start)
- [Deployment](#-deployment)
- [Configuration](#-configuration)
- [Monitoring](#-monitoring)
- [Troubleshooting](#-troubleshooting)
- [API Documentation](#-api-documentation)

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    1. DATA COLLECTION LAYER                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   CoinGecko  â”‚  â†’   â”‚   Producer   â”‚  â†’   â”‚   Redpanda   â”‚  â”‚
â”‚  â”‚     API      â”‚      â”‚  (10 mins)   â”‚      â”‚    Cloud     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    2. PROCESSING LAYER                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Consumer   â”‚  â†’   â”‚ Redis Upstashâ”‚  +   â”‚   Supabase   â”‚  â”‚
â”‚  â”‚  (Real-time) â”‚      â”‚ (Hot Cache)  â”‚      â”‚ (PostgreSQL) â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    3. ANALYTICS LAYER                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚  â”‚  Stats DAG   â”‚      â”‚Prediction DAGâ”‚                         â”‚
â”‚  â”‚  (Daily)     â”‚      â”‚  (Nightly)   â”‚      Apache Airflow     â”‚
â”‚  â”‚  High/Low/   â”‚      â”‚  Prophet ML  â”‚                         â”‚
â”‚  â”‚  Volatility  â”‚      â”‚  Forecasts   â”‚                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    4. PRESENTATION LAYER                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                 Reflex Frontend (React)                    â”‚ â”‚
â”‚  â”‚  â€¢ Real-time Dashboard   â€¢ Price Charts   â€¢ Predictions   â”‚ â”‚
â”‚  â”‚  â€¢ Historical Analysis   â€¢ Alerts         â€¢ WebSockets    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Details

| Layer | Component | Technology | Purpose | Status |
|-------|-----------|------------|---------|--------|
| **Data Collection** | Producer | Python + kafka-python | Fetches prices from CoinGecko every 10 min | âœ… Working |
| | Broker | Redpanda Cloud | Kafka-compatible message streaming | âœ… Working |
| **Processing** | Consumer | Python + asyncio | Consumes messages, dual-writes | âœ… Working |
| | Hot Cache | Redis Upstash | Latest price caching (~ms latency) | âœ… Working |
| | Database | Supabase PostgreSQL | Historical data storage | âœ… Working |
| **Analytics** | Stats DAG | Airflow + Python | Daily statistics (24h/7d/30d) | âš ï¸ Ready |
| | Prediction DAG | Airflow + Prophet | Nightly ML forecasts | âš ï¸ Ready |
| **Presentation** | Frontend | Reflex (Python â†’ React) | Real-time dashboard | ğŸ”„ WIP |

---

## âœ¨ Features

### Real-Time Data Pipeline
- **10-minute intervals**: Automatic price fetching from CoinGecko API
- **Dual storage**: Hot cache (Redis) + persistent history (PostgreSQL)
- **Retry logic**: Exponential backoff for connection failures
- **Monitoring**: Comprehensive logging and health checks

### Analytics & Statistics
- **Time periods**: 24 hours, 7 days, 30 days
- **Metrics**: High, Low, Average, Volatility
- **Automation**: Runs daily at midnight UTC
- **Storage**: Results stored in Supabase for dashboard display

### ML Predictions
- **Models**: Prophet (default), ARIMA, LSTM, Simple MA
- **Forecasts**: 1 hour, 24 hours, 7 days ahead
- **Confidence**: Prediction confidence scores (0-1)
- **Trend analysis**: BULLISH, BEARISH, NEUTRAL indicators
- **Schedule**: Runs nightly at 22:00 UTC

### Cloud-Native Infrastructure
- **Redpanda Cloud**: Globally distributed Kafka broker
- **Supabase**: Managed PostgreSQL with REST API
- **Redis Upstash**: Serverless Redis with global replication
- **Docker**: Container orchestration for Airflow

---

## ğŸ“¦ Prerequisites

### Required
- **Python 3.11+** with pip and venv
- **Git** for version control
- **Linux/macOS** (or WSL on Windows)

### Optional
- **Docker & Docker Compose** (for Airflow)
- **Node.js 18+** (if modifying frontend)

### Cloud Services (Already Configured)
- âœ… Redpanda Cloud cluster
- âœ… Supabase project with tables
- âœ… Redis Upstash instance
- âœ… CoinGecko API (free tier)

---

## ğŸš€ Quick Start

### 1. Clone & Setup

```bash
git clone https://github.com/ThiruEigen7/Belly---Beldex-Crypto-Real-Time-Monitor-for-Appa.git
cd belly

# Create virtual environment
python3 -m venv env
source env/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Configure Environment

```bash
# Copy production environment template
cp .env.production .env

# Edit .env and verify credentials (already filled)
nano .env
```

### 3. Apply Database Migrations

Run this SQL in [Supabase SQL Editor](https://supabase.com/dashboard/project/bcioieesyhilfrfgogpq/sql/new):

```sql
-- Copy contents from: belly/zebra/migrations/001_update_predictions_schema.sql
```

### 4. Deploy Everything

```bash
# One-command deployment
./deploy.sh
```

This will:
- âœ… Check prerequisites
- âœ… Apply migrations (manual prompt)
- âœ… Start Producer (background)
- âœ… Start Consumer (background)
- âœ… Start Airflow (Docker)
- âœ… Optionally start Frontend

---

## ğŸ® Deployment

### Production Deployment (Recommended)

```bash
# Full stack deployment
./deploy.sh

# Access services:
# - Airflow UI: http://localhost:8080 (admin/admin123)
# - Frontend: http://localhost:3000 (if enabled)
```

### Manual Deployment (Component-wise)

#### Streaming Layer Only
```bash
source env/bin/activate

# Start producer
python belly/streaming/producer.py &

# Start consumer
python belly/streaming/consumer.py &
```

#### Airflow Only
```bash
cd belly/airflow
docker-compose -f docker-compose.production.yml up -d
```

### Stopping Services

```bash
# Stop all services
./scripts/stop.sh

# Or manually:
# Stop Python processes
kill $(cat logs/producer.pid)
kill $(cat logs/consumer.pid)

# Stop Airflow
cd belly/airflow && docker-compose -f docker-compose.production.yml down
```

---

## âš™ï¸ Configuration

### Environment Variables

All configuration is in `.env` file:

```bash
# === CORE SERVICES ===
SUPABASE_URL=https://bcioieesyhilfrfgogpq.supabase.co
SUPABASE_ANON_KEY=eyJhbGci...

REDIS_URL=https://settling-locust-8886.upstash.io
REDIS_TOKEN=ASK2AAImcD...

KAFKA_BROKERS=d4qn7d0e5lrisl4hsue0.any.us-central1.gc.prd.cloud.redpanda.com:9092
KAFKA_USERNAME=crypto
KAFKA_PASSWORD=9cN1b0InCHDM5BmAmcEXmDytVvf9tB

# === STREAMING CONFIG ===
FETCH_INTERVAL=600  # 10 minutes (in seconds)

# === ML CONFIG ===
PREDICTION_MODEL=prophet  # prophet, arima, lstm, simple_ma
PREDICTION_LOOKBACK_DAYS=30

# === AIRFLOW CONFIG ===
AIRFLOW_USERNAME=admin
AIRFLOW_PASSWORD=admin123
```

### Adjusting Fetch Interval

To change price fetch frequency:

```bash
# In .env file:
FETCH_INTERVAL=300  # 5 minutes
FETCH_INTERVAL=600  # 10 minutes (default)
FETCH_INTERVAL=900  # 15 minutes
```

Then restart producer:
```bash
kill $(cat logs/producer.pid)
source env/bin/activate
python belly/streaming/producer.py &
```

---

## ğŸ“Š Monitoring

### Check Service Status

```bash
./scripts/status.sh
```

Output example:
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          BELLY - System Status                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“¡ Streaming Layer:
  âœ… Producer: Running (PID: 12345)
  âœ… Consumer: Running (PID: 12346)

ğŸ”§ Airflow:
  âœ… Airflow Webserver: Running
  âœ… Airflow Scheduler: Running
```

### View Logs

```bash
# Real-time producer logs
tail -f logs/producer.log

# Real-time consumer logs
tail -f logs/consumer.log

# Airflow logs (Docker)
cd belly/airflow
docker-compose -f docker-compose.production.yml logs -f
```

### Health Endpoints

```bash
# Check if producer is fetching prices
grep "Fetched price" logs/producer.log | tail -5

# Check consumer writes
grep "Written to Database" logs/consumer.log | tail -5

# Airflow health
curl http://localhost:8080/health
```

---

## ğŸ› Troubleshooting

### Producer Not Connecting to Redpanda

**Symptom**: `NoBrokersAvailable` error

**Solution**:
```bash
# Check network connectivity
ping d4qn7d0e5lrisl4hsue0.any.us-central1.gc.prd.cloud.redpanda.com

# Verify credentials in .env
grep KAFKA_ .env

# Check producer logs
tail -n 50 logs/producer.log

# Restart with retry logic (automatic)
kill $(cat logs/producer.pid)
python belly/streaming/producer.py &
```

### Consumer Not Writing to Supabase

**Symptom**: Consumer running but no data in database

**Solution**:
```bash
# Test Supabase connection
python3 -c "
from belly.zebra.services.db_service import DatabaseService
import asyncio
async def test():
    db = DatabaseService()
    await db.connect()
    print('Connected:', db.connected)
asyncio.run(test())
"

# Check ACL permissions in Redpanda Console
# Verify topic "belly-price" has ALL permissions
# Verify consumer group "*" has READ permission
```

###Airflow DAGs Not Appearing

**Symptom**: Empty DAG list in Airflow UI

**Solution**:
```bash
# Check if DAGs are mounted
docker exec -it belly-airflow-scheduler ls /home/airflow/dags

# Restart scheduler
cd belly/airflow
docker-compose -f docker-compose.production.yml restart airflow-scheduler

# Check for Python syntax errors
cd belly/airflow
python -m py_compile dags/stats_dag.py
python -m py_compile dags/prediction_dag.py
```

### Database Migration Errors

**Symptom**: DAG fails with "column does not exist"

**Solution**:
```sql
-- Run in Supabase SQL Editor:
-- 1. Check existing columns
SELECT column_name, data_type 
FROM information_schema.columns 
WHERE table_name = 'predictions';

-- 2. Apply migration manually
-- Copy from: belly/zebra/migrations/001_update_predictions_schema.sql
```

---

## ğŸ“š API Documentation

### Supabase REST API

Base URL: `https://bcioieesyhilfrfgogpq.supabase.co/rest/v1`

#### Get Latest Price
```bash
curl -X GET "https://bcioieesyhilfrfgogpq.supabase.co/rest/v1/price_history?order=timestamp.desc&limit=1" \
  -H "apikey: YOUR_ANON_KEY" \
  -H "Authorization: Bearer YOUR_ANON_KEY"
```

#### Get Price History
```bash
curl -X GET "https://bcioieesyhilfrfgogpq.supabase.co/rest/v1/price_history?order=timestamp.desc&limit=100" \
  -H "apikey: YOUR_ANON_KEY" \
  -H "Authorization: Bearer YOUR_ANON_KEY"
```

#### Get Stats
```bash
curl -X GET "https://bcioieesyhilfrfgogpq.supabase.co/rest/v1/stats?period=eq.24h&order=computed_at.desc&limit=1" \
  -H "apikey: YOUR_ANON_KEY" \
  -H "Authorization: Bearer YOUR_ANON_KEY"
```

#### Get Predictions
```bash
curl -X GET "https://bcioieesyhilfrfgogpq.supabase.co/rest/v1/predictions?order=generated_at.desc&limit=1" \
  -H "apikey: YOUR_ANON_KEY" \
  -H "Authorization: Bearer YOUR_ANON_KEY"
```

### Redis Upstash API

```bash
# Get current price
curl https://settling-locust-8886.upstash.io/get/beldex:current_price \
  -H "Authorization: Bearer YOUR_REDIS_TOKEN"
```

---

## ğŸ¨ Frontend Development

### Running Reflex Frontend

```bash
source env/bin/activate
reflex init  # First time only
reflex run
```

Access at: `http://localhost:3000`

### Building for Production

```bash
reflex export
```

---

## ğŸ“ˆ Performance Metrics

### Current Performance

| Metric | Value | Target |
|--------|-------|--------|
| Producer Fetch Interval | 10 mins | âœ… Met |
| Consumer Latency | <2s | âœ… Met |
| Redis Cache Hit Rate | ~95% | âœ… Met |
| Supabase Query Time | <500ms | âœ… Met |
| Airflow DAG Success Rate | TBD | 99% |

### Scalability

- **Price History**: 144 records/day Ã— 365 days = 52,560 records/year
- **Database Size**: ~5 MB/year (price_history + stats + predictions)
- **Redis Memory**: <10 MB (current price only)
- **Kafka Messages**: Retained for 7 days (~1,000 messages)

---

## ğŸ” Security

### Best Practices
- âœ… Environment variables in `.env` (gitignored)
- âœ… SASL/SSL authentication for Kafka
- âœ… API key authentication for Supabase
- âœ… Token-based auth for Redis Upstash
- âš ï¸ Airflow UI exposed on localhost only

### Production Hardening
- [ ] Enable Supabase Row Level Security (RLS)
- [ ] Add rate limiting to APIs
- [ ] Use secrets manager (AWS Secrets Manager, etc.)
- [ ] Enable Airflow RBAC with strong passwords
- [ ] Add SSL/TLS for frontend

---

## ğŸ“ Support

### Documentation
- **Airflow**: `belly/airflow/README.md`
- **Streaming**: `belly/streaming/README.md`
- **Database Schema**: `belly/zebra/init-db.sql`

### Useful Commands

```bash
# View all running processes
ps aux | grep -E "producer|consumer|airflow"

# Check disk usage
du -sh logs/
du -sh belly/

# View environment
env | grep -E "SUPABASE|REDIS|KAFKA"

# Test connections
python test_streaming_end_to_end.py
```

---

## ğŸ¯ Roadmap

### Phase 1 - Core Infrastructure âœ…
- [x] Streaming pipeline (Producer â†’ Redpanda â†’ Consumer)
- [x] Dual storage (Redis + Supabase)
- [x] Airflow DAGs (Stats + Predictions)
- [x] Production deployment scripts

### Phase 2 - Frontend & UX ğŸ”„
- [ ] Real-time dashboard with charts
- [ ] Historical price graphs
- [ ] Prediction visualization
- [ ] Alert notifications

### Phase 3 - Advanced Features ğŸ”®
- [ ] Multiple cryptocurrencies support
- [ ] Advanced ML models (Transformer, GNN)
- [ ] Sentiment analysis from Twitter/Reddit
- [ ] Portfolio tracking
- [ ] Mobile app (React Native)

---

## ğŸ“„ License

MIT License - See LICENSE file for details

---

## ğŸ‘¥ Contributors

- **ThiruEigen7** - Project Lead & Development

---

## ğŸ™ Acknowledgments

- **CoinGecko** - Free crypto price API
- **Redpanda** - Cloud Kafka platform
- **Supabase** - PostgreSQL backend
- **Upstash** - Serverless Redis
- **Apache Airflow** - Workflow orchestration
- **Prophet** - Time series forecasting by Meta

---

**Built with â¤ï¸ for the crypto community**
